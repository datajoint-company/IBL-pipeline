#!/bin/bash --login

# IBL Alyx Entrypoint Script
# ==========================

err_exit() {
	set -e
	echo "#! Error: $*" >&2
	return 1
}

# globals
# -------

# get this script file and its parent directory name (no symlink resolution)
script_cmd="${BASH_SOURCE[0]}"
script_path="$(cd "$(dirname ${script_cmd})" &>/dev/null && pwd)"
script_file=$(basename "${script_cmd}")
shell_dir=$PWD

# use default dockerfile directory if root path not specified
[[ -z "${IBL_PATH_ROOT}" ]] && IBL_PATH_ROOT=/int-brain-lab

# get alyx source code directory or default to /var/www/alyx-main/alyx
[[ -z "${IBL_PATH_ALYX}" ]] && IBL_PATH_ALYX=/var/www/alyx-main/alyx

# get data directory or default to IBL_PATH_ROOT/data
[[ -z "${IBL_PATH_DATA}" ]] && IBL_PATH_DATA="${IBL_PATH_ROOT}/data"

# get current date as default
[[ -z "${ALYX_DL_DATE}" ]] && ALYX_DL_DATE=$(date -u +'%Y-%m-%d')

# default flatiron server url
[[ -z "${FLATIRON_SERVER}" ]] && FLATIRON_SERVER=https://ibl.flatironinstitute.org

# dump/misc variables
ALYX_DUMP_URL=
ALYX_DUMP_FILE=
ALYX_DUMP_EXPIRES=6
ALYX_DUMP_DIR="${IBL_PATH_DATA}/alyx/dumps"
DISABLE_MAIL=true

# paths of alyx files used during db setup/interaction steps
alyx_manager="${IBL_PATH_ALYX}/alyx/manage.py"
db_loaded_file="${IBL_PATH_DATA}/alyx/db_loaded"
su_created_file="${IBL_PATH_DATA}/alyx/superuser_created"
alyx_server_start_file="${alyx_server_start_file:-${IBL_PATH_ROOT}/alyx_start_server.out}"
alyx_lock_file="/tmp/._alyx.lock"
alyx_token_fixture="${IBL_PATH_DATA}/alyx/auth.token.backup.json"

# help documentation
# ------------------

show_help() {
	echo "usage: $script_file [OPTION]... FUNC/ROUTINE...

Entrypoint for Alyx database management

Options:

--dump_date=ALYX_DL_DATE ....... Date used to fetch database dump in YYYY-mm-dd format.
--dump_url=ALYX_DUMP_URL ....... Full url of sql dump instead of using ALYX_DL_DATE
                                 to form the url.
--dump_file=ALYX_DUMP_FILE ..... Path to store or load local copy of SQL dump, defaults
                                 to file formed via ALYX_DL_DATE.
--dump_exp=ALYX_DUMP_EXPIRES ... Number of days for dumps to be considered expired when
                                 using function 'clean_dls'.
                                 Default is ${ALYX_DUMP_EXPIRES} days.


Functions:

create_dbs ..... Create new, empty '${PGDATABASE}' and '${PGDATABASE}_old' postgres
                 databases if they do not already exist.
config_alyx .... Configure Alyx/django settings. The environment variables
                 PGUSER PGHOST and PGPASSWORD are required.
update_alyx .... Make migrations, migrate, load fixtures, set permissions, create su.
fetch_dump ..... Download Alyx database dump from the date set in env variable
                 ALYX_DL_DATE or from the option --dump_url.
load_db ........ Load data from the sql dump into postgres '${PGDATABASE}' database if
                 file '${db_loaded_file}' does not already exist.
dump_json ...... Send request to Alyx to perform a JSON dump of the current database.
                 Database stored at '${ALYX_DUMP_DIR}/json'
dump_sql ....... Send request to Alyx to perform a SQL dump of the current database.
                 Database stored at '${ALYX_DUMP_DIR}/sql'
clean_dls ...... Clean up existing sql dumps in sql dump folder.
                 Use with option '--dump_exp'.
reset_alyx ..... Reset '${PGDATABASE}' to empty. Won't load database.
start_server ... Start Alyx server using port '${ALYX_PORT}'.
check_server ... Check if Alyx is up and running.
kill_server .... Kill process for the 'manage.py runserver' command.

Routines:

init_db ............... Routine that performs all initialization steps to bring up the
                        '${PGDATABASE}' database by running: create_dbs, ...
                        config_alyx, update_alyx.
fetch_and_load_db ..... Routine that inserts the latest sql dump into the postgres
                        '${PGDATABASE}' database by running: fetch_dump, load_db.
fetch_and_reload_db ... Routine that inserts the latest sql dump and resets
                        '${PGDATABASE}' by running: fetch_dump, load_db --reset.
www ................... Routine that initializes environment and runs the web server
                        by running: init_db, fetch_and_load_db, start_server
www_no_load ........... Routine that initializes environment and runs the web server
                        by running: init_db, start_server
dev ................... Wait indefinitely.

Environment Variables (available if script is sourced):

  IBL_PATH_ROOT=${IBL_PATH_ROOT}
  IBL_PATH_ALYX=${IBL_PATH_ALYX}
  IBL_PATH_DATA=${IBL_PATH_DATA}
  PGDATABASE=${PGDATABASE}
  PGHOST=${PGHOST}
  PGUSER=${PGUSER}
  PGPASSWORD=******
  ALYX_DL_DATE=${ALYX_DL_DATE}
  ALYX_DUMP_FILE=${ALYX_DUMP_FILE}
  ALYX_DUMP_DIR=${ALYX_DUMP_DIR}
  ALYX_PORT=${ALYX_PORT}


Database File Status:

  db_loaded: $(test -f ${db_loaded_file} && echo "YES" || echo "NO")


Examples:

 Run operations in a specific order

   $script_file fetch_dump create_dbs load_db

 Fetch and load dump from specific date

   $script_file --dump_date=2021-10-07 fetch_and_reload_db

 Clean existing sql dumps older than 3 days

   $script_file --dump_exp=3 clean_dls

 Source the variables and functions in this script

   source $script_file
   manage_alyx help
"
	exit 0
}

# flag to show help after some variables are populated
SHOW_HELP=0

# stores set of db functions to run in sequence
OPS_SEQ=()

# handle input arguments
while [[ $# -gt 0 ]]; do
	case "$1" in
	--dump_date=*)
		ALYX_DL_DATE="${1#*=}"
		echo "--dump_date passed. Using dump date: '${ALYX_DL_DATE}'"
		shift
		;;
	--dump_url=*)
		ALYX_DUMP_URL="${1#*=}"
		echo "--dump_url passed. Using dump url: '${ALYX_DUMP_URL}'"
		shift
		;;
	--dump_file=*)
		export ALYX_DUMP_FILE="${1#*=}"
		echo "--dump_file passed. Using dump file: '${ALYX_DUMP_FILE}'"
		shift
		;;
	--dump_exp=*)
		ALYX_DUMP_EXPIRES="${1#*=}"
		echo "--dump_exp passed. Using dump expiration: '${ALYX_DUMP_EXPIRES}' days"
		shift
		;;
	--reset_db_loaded_file)
		rm -f "${db_loaded_file}"
		echo "--reset_db_loaded_file passed. Removing '${db_loaded_file}'"
		shift
		;;
	"help" | "--help" | "-h" | "--help")
		SHOW_HELP=1
		break
		;;
	"dev")
		OPS_SEQ+=("run_dev")
		shift
		;;
	"fetch_dump")
		OPS_SEQ+=("fetch_dump")
		shift
		;;
	"create_dbs")
		OPS_SEQ+=("create_dbs")
		shift
		;;
	"config_alyx")
		OPS_SEQ+=("config_alyx")
		shift
		;;
	"create_su")
		OPS_SEQ+=("create_su")
		shift
		;;
	"update_alyx")
		OPS_SEQ+=("update_alyx")
		shift
		;;
	"start_server")
		OPS_SEQ+=("start_server")
		shift
		;;
	"check_server")
		OPS_SEQ+=("check_server")
		shift
		;;
	"kill_server")
		OPS_SEQ+=("kill_server")
		shift
		;;
	"load_db")
		OPS_SEQ+=("load_db")
		shift
		;;
	"reset_alyx")
		OPS_SEQ+=("reset_alyx")
		shift
		;;
	"dump_json")
		OPS_SEQ+=("dump_json")
		shift
		;;
	"dump_sql")
		OPS_SEQ+=("dump_sql")
		shift
		;;
	"clean_dls")
		OPS_SEQ+=("clean_dls")
		shift
		;;
	"test_alyx")
		OPS_SEQ+=("test_alyx")
		shift
		;;
	"init_db")
		OPS_SEQ+=("init_db")
		shift
		;;
	"fetch_and_load_db")
		OPS_SEQ+=("fetch_and_load_db")
		shift
		;;
	"www")
		OPS_SEQ+=("www")
		shift
		;;
	"www_no_load")
		OPS_SEQ+=("www_no_load")
		shift
		;;
	"fetch_and_reload_db")
		OPS_SEQ+=("fetch_and_reload_db")
		shift
		;;
	"-")
		shift
		;;
	"--")
		shift
		echo "Stopping arg parse. Rest of command: $*"
		break
		;;
	*)
		err_exit "Unknown option: '$1'. Use '--' for no option."
		;;
	esac
done

# write ALYX_DUMP_FILE after any options passed
if [[ -z "${ALYX_DUMP_FILE}" ]]; then
	# where to save/load sql dump
	export ALYX_DUMP_FILE="${ALYX_DUMP_DIR}/sql/${ALYX_DL_DATE}_alyxfull.sql.gz"
fi

# show help if asked
# ------------------

[[ ${SHOW_HELP} -eq 1 ]] && show_help

# other checks
# ------------

# check that a central database name exists
[[ -z "${PGDATABASE}" ]] &&
	err_exit "database name environment variable PGDATABASE is not set"

# check that IBL path is a directory that exists
[[ -d "${IBL_PATH_ROOT}" ]] ||
	err_exit "path '${IBL_PATH_ROOT}' from IBL_PATH_ROOT does not exist"

# check that Alyx path is a directory that exists
[[ -d "${IBL_PATH_ALYX}" ]] ||
	err_exit "path '${IBL_PATH_ALYX}' from IBL_PATH_ALYX does not exist"

# check that IBL data path is a directory that exists
[[ -d "${IBL_PATH_DATA}" ]] ||
	err_exit "path '${IBL_PATH_DATA}' from IBL_PATH_DATA does not exist"

# check for django python script manager
[[ -f "${alyx_manager}" ]] ||
	err_exit "can't locate '${alyx_manager}'," \
		"check alyx source code path IBL_PATH_ALYX='${IBL_PATH_ALYX}'"

# make these additional directories if they don't exist
[[ -d "${ALYX_DUMP_DIR}/sql" ]] || mkdir -p "${ALYX_DUMP_DIR}/sql"
[[ -d "${ALYX_DUMP_DIR}/json" ]] || mkdir -p "${ALYX_DUMP_DIR}/json"
[[ -d "${ALYX_DUMP_DIR}/backup" ]] || mkdir -p "${ALYX_DUMP_DIR}/backup"

# helpers
# -------

check_db() {
	local datname="$1"
	[[ -z "${datname}" ]] && datname="${PGDATABASE}"
	echo "# => checking for existing database '${datname}'"
	DB_NAME_EXISTS=0
	[[ $(psql -tAc "SELECT 1 FROM pg_database WHERE datname='${datname}';") == "1" ]] &&
		DB_NAME_EXISTS=1
	if [[ ${DB_NAME_EXISTS} -eq 0 ]] && [[ "$2" == "-e" ]]; then
		err_exit "database '${datname}' does not yet exist, run 'create_dbs' first," \
			"or create the database manually"
	fi
}

check_db_usr() {
	local usename="$1"
	[[ -z "${usename}" ]] && usename="${PGUSER}"
	echo "# => checking for existing database user '${usename}'"
	DB_USER_EXISTS=0
	[[ $(psql -tAc "SELECT 1 FROM pg_user WHERE usename  = '${usename}';") == "1" ]] &&
		DB_USER_EXISTS=1
	if [[ ${DB_USER_EXISTS} -eq 0 ]] && [[ "$2" == "-e" ]]; then
		err_exit "database does not have a user named '${usename}'"
	fi
}

check_url() {
	local chkurl="$1"
	shift
	[[ -z "${chkurl}" ]] && err_exit "check_url() requires at least 1 input arg"
	echo "# => checking for a valid flatiron URL: $chkurl"
	local response=$(wget --server-response --spider $chkurl "$@" 2>&1)
	CONNECTION_ESTABLISHED=1
	if [[ ! $(echo "$response" 2>&1 | grep 'HTTP/1.1 200 OK') ]] ||
		[[ ! $(echo "$response" 2>&1 | grep 'Connection: Keep-Alive') ]]; then
		echo "#~ Warning: could not connect to: '$chkurl' w/ '$*'"
		echo "$response"
		CONNECTION_ESTABLISHED=0
	fi
}

manage_alyx() {
	local acmd="$1"
	shift
	[[ -z "${acmd}" ]] && acmd=help
	python "${alyx_manager}" "${acmd}" "$@"
}

run_dev() {
	echo -e "\nStarting development environment...\n"
	while :; do
		sleep 10
	done
}

run_function_seq() {
	local fn
	if [[ $# -gt 0 ]]; then
		echo "# > operation sequence: $*"
		for fn in "$@"; do
			echo "# >> ${fn}()"
			$fn
		done
	fi
}

lock_alyx_op() {
	if [[ "${1}" = "-c" ]]; then
		local ts_now=$(date +"%s")
		local break_after=${2:-600}
		while [[ -f "${alyx_lock_file}" ]]; do
			echo "... waiting for end of running alyx process"
			sleep 10
			[[ $(($(date +"%s") - $ts_now)) -gt ${break_after} ]] && break
		done
	elif [[ "${1}" = "-r" ]]; then
		rm -vf "${alyx_lock_file}"
	else
		touch "${alyx_lock_file}"
	fi
}

# functions for postgres/django operations
# ----------------------------------------

create_dbs() {
	pg_isready
	local pg_status=$?
	[[ $pg_status -gt 0 ]] && err_exit "postgres not accepting connections"
	createdb 2>/dev/null

	check_db "${PGDATABASE}"
	if [[ ${DB_NAME_EXISTS} -eq 0 ]]; then
		echo "# => creating database ${PGDATABASE}"
		psql -c "CREATE DATABASE \"${PGDATABASE}\";"
	fi

	check_db "${PGDATABASE}_old"
	if [[ ${DB_NAME_EXISTS} -eq 0 ]]; then
		echo "# => creating database ${PGDATABASE}_old"
		psql -c "CREATE DATABASE \"${PGDATABASE}_old\";"
	fi

	# stop postgres container warnings
	check_db root
	if [[ ${DB_NAME_EXISTS} -eq 0 ]]; then
		psql -c "CREATE USER root WITH PASSWORD 'root';"
		psql -c "CREATE DATABASE root;"
	fi

	check_db_usr ${PGUSER} -e
	psql -c "ALTER ROLE ${PGUSER} SET client_encoding TO 'utf8';" >/dev/null
	psql -c "ALTER ROLE ${PGUSER} SET default_transaction_isolation TO 'read committed';" >/dev/null
	psql -c "ALTER ROLE ${PGUSER} SET timezone TO 'UTC';" >/dev/null
	psql -c "GRANT ALL PRIVILEGES ON DATABASE \"${PGDATABASE}\" TO \"${PGUSER}\";" >/dev/null
	psql -c "ALTER USER ${PGUSER} WITH CREATEROLE;" >/dev/null
	psql -c "ALTER USER ${PGUSER} WITH SUPERUSER;" >/dev/null
	psql -c "ALTER USER ${PGUSER} WITH CREATEDB;" >/dev/null
}

fetch_dump() {
	if [[ -f "${ALYX_DUMP_FILE}" ]]; then
		echo "# => Found existing alyx dump file '${ALYX_DUMP_FILE}'." \
			"Will not attempt redownload." \
			"Run 'rm -f ${ALYX_DUMP_FILE}' to forcibly remove" \
			"the file then re-attempt download"
	else
		[[ -z "${FLATIRON_SERVER_LOGIN}" ]] &&
			err_exit "FLATIRON_SERVER_LOGIN environment variable is not set"
		[[ -z "${FLATIRON_SERVER_PWD}" ]] &&
			err_exit "FLATIRON_SERVER_PWD environment variable is not set"

		local url="${ALYX_DUMP_URL}"
		[[ -z "${url}" ]] &&
			url="${FLATIRON_SERVER}/json/${ALYX_DL_DATE}_alyxfull.sql.gz"

		check_url "$url" \
			--user "${FLATIRON_SERVER_LOGIN}" --password "${FLATIRON_SERVER_PWD}"

		if [[ $CONNECTION_ESTABLISHED -eq 0 ]]; then
			unset ALYX_DUMP_FILE
		else
			mkdir -p $(dirname "${ALYX_DUMP_FILE}")
			echo "# => Downloading database dump from '$url' ..."
			wget -q -O ${ALYX_DUMP_FILE} \
				--user "$FLATIRON_SERVER_LOGIN" \
				--password "$FLATIRON_SERVER_PWD" \
				"${url}"
			echo "# ==> download complete, saved to file: '${ALYX_DUMP_FILE}'"
		fi
	fi
}

clean_dls() {
	echo "# => current disk usage for '${IBL_PATH_DATA}'"
	du -h --max-depth=2 ${IBL_PATH_DATA} | sort -h

	local old_dumps=$(find "${ALYX_DUMP_DIR}/sql" -type f \
		-mmin +$((${ALYX_DUMP_EXPIRES} * 60 * 24)) 2>/dev/null)
	if [[ ! -z ${old_dumps} ]]; then
		echo "# => cleaning sql dumps ${old_dumps}"
		rm -f ${old_dumps}
	else
		echo "# => no sql dumps to clean from $(ls -lh ${ALYX_DUMP_DIR}/sql)"
	fi

	local cache_dir="${IBL_PATH_DATA}/alyx/cache"
	echo "# ==> cleaning cache files from '$cache_dir'"
	find "${cache_dir}" -mindepth 1 ! -type d -not -name histology -printf '%s %p\n'
	sudo whoami >/dev/null
	sudo find "${cache_dir}" -mindepth 1 ! -type d -not -name histology -delete
}

config_alyx() {
	echo "# => configuring alyx"

	echo "# ==> checking if environment variables and databases exist"
	[[ -z "${PGUSER}" ]] && err_exit "PGUSER environment variable is not set"
	[[ -z "$PGPASSWORD" ]] && err_exit "PGPASSWORD environment variable is not set"
	[[ -z "${PGHOST}" ]] && err_exit "PGHOST environment variable is not set"
	[[ -z "$DJANGO_SECRET_KEY" ]] && err_exit "DJANGO_SECRET_KEY environment variable is not set"

	# custom settings_secret for multiple DBs
	echo "# ==> configuring settings_*.py"

	sed \
		-e "s/%SECRET_KEY%/$DJANGO_SECRET_KEY/" \
		-e "s/%DBNAME%/${PGDATABASE}/" \
		-e "s/%DBUSER%/${PGUSER}/" \
		-e "s/%DBPASSWORD%/$PGPASSWORD/" \
		-e "s/127.0.0.1/${PGHOST}/" \
		>"${IBL_PATH_ALYX}/alyx/alyx/settings_secret.py" <<-EOF
			SECRET_KEY  = '%SECRET_KEY%'

			DATABASES  = {
			    'default': {
			        'ENGINE': 'django.db.backends.postgresql_psycopg2',
			        'NAME': '%DBNAME%',
			        'USER': '%DBUSER%',
			        'PASSWORD': '%DBPASSWORD%',
			        'HOST': '127.0.0.1',
			        'PORT': '5432',
			    },
			    'old': {
			        'ENGINE': 'django.db.backends.postgresql_psycopg2',
			        'NAME': '%DBNAME%_old',
			        'USER': '%DBUSER%',
			        'PASSWORD': '%DBPASSWORD%',
			        'HOST': '127.0.0.1',
			        'PORT': '5432',
			    }
			}

			EMAIL_HOST = 'mail.superserver.net'
			EMAIL_HOST_USER = 'alyx@awesomedomain.org'
			EMAIL_HOST_PASSWORD = 'UnbreakablePassword'
			EMAIL_PORT = 587
			EMAIL_USE_TLS = True
		EOF

	awk \
		-v USERNAME="${PGUSER}" \
		'{
			sub(/'\''alyx.internationalbrainlab.org'\''/,"\"alyx.internationalbrainlab.org\", \"alyx\"");
			sub(/'\''root'\'',/,"\"root\", \"" USERNAME "\",");
		} 1' "${IBL_PATH_ALYX}/alyx/alyx/settings_lab_template.py" >"${IBL_PATH_ALYX}/alyx/alyx/settings_lab.py"

	awk \
		'{
			sub(/DEBUG \= False/,"DEBUG = True");
		} 1' "${IBL_PATH_ALYX}/alyx/alyx/settings_template.py" >"${IBL_PATH_ALYX}/alyx/alyx/settings.py"

	echo "# ==> configuring apache2"
	local condaenvpath="/opt/local/conda/envs/${CONDA_ENV_USER}"
	local condaenvpkgs="${condaenvpath}/lib/python3.9/site-packages"

	awk \
		-v USERNAME="$(id -un)" \
		-v GROUPNAME=$(id -Gn) \
		-v CENVPTH="${condaenvpath}" \
		-v ALYXROOT="${IBL_PATH_ALYX}" \
		-v CENVPKG="${condaenvpkgs}" '{
			sub(/LogLevel info/,"LogLevel error");
			sub(/alyx.internationalbrainlab.org/,"localhost\n        ServerAlias alyx");
			sub(/python-path=\/var\/www\/alyx\/alyx/,"python-path=" CENVPKG );
			sub(/python-home=\/var\/www\/alyx\/alyxvenv/,"python-home=" CENVPTH );
			sub(/WSGIDaemonProcess alyx python-path/,"WSGIDaemonProcess alyx user=" USERNAME " group=" GROUPNAME " python-path");
			sub(/\/var\/www\/alyx\/alyx/,ALYXROOT );
		} 1' "${IBL_PATH_ALYX}/docs/_static/001-alyx.conf" >/etc/apache2/sites-available/001-alyx.conf

	if [[ ! $(cat /etc/apache2/apache2.conf | grep ${HOSTNAME}) ]]; then
		sudo whoami >/dev/null
		sudo chmod a+w /etc/apache2/apache2.conf
		echo "ServerName ${HOSTNAME}" >>/etc/apache2/apache2.conf
		sudo chmod 644 /etc/apache2/apache2.conf
	fi

	mod_wsgi-express module-config >/etc/apache2/mods-available/wsgi.load

	echo "# ==> configuring .pgpass"
	rm -f ~/.pgpass
	install -m 0600 /dev/null ~/.pgpass
	echo "${PGHOST}:5432:${PGDATABASE}:${PGUSER}:${PGPASSWORD}" >>~/.pgpass
}

create_su() {
	if [[ ! -f "${su_created_file}" ]]; then
		echo "# => creating superuser"

		manage_alyx shell <<-EOF
			try:
			    from misc.models import LabMember
			    LabMember.objects.create_superuser(
			        username="${PGUSER}",
			        email="info@datajoint.com",
			        password="$PGPASSWORD",
			        is_stock_manager=True,
			    )
			except Exception as e:
			    print(e)
		EOF

		echo "# ==> creating superuser token"
		manage_alyx drf_create_token "${PGUSER}"

		echo "# ==> setting user permissions"
		manage_alyx set_user_permissions

		echo "# ==> dumping tokens for db reset"
		manage_alyx dumpdata --indent 1 misc.labmember authtoken >"${alyx_token_fixture}"

		echo "${PGUSER}" >"${su_created_file}"
	fi
}

load_alyx_fixtures() {
	echo "# => loading fixtures"
	local fixture_list=(
		actions/fixtures/actions.proceduretype.json
		actions/fixtures/actions.watertype.json
		actions/fixtures/actions.cullreason.json
		data/fixtures/data.datarepositorytype.json
		data/fixtures/data.dataformat.json
		data/fixtures/data.datasettype.json
		misc/fixtures/misc.cagetype.json
		misc/fixtures/misc.enrichment.json
		misc/fixtures/misc.food.json
		subjects/fixtures/subjects.source.json
		experiments/fixtures/experiments.coordinatesystem.json
		experiments/fixtures/experiments.probemodel.json
		experiments/fixtures/experiments.brainregion.json
	)

	[[ -f "${alyx_token_fixture}" ]] && fixture_list+=("${alyx_token_fixture}")

	local fx
	for fx in "${fixture_list[@]}"; do
		manage_alyx loaddata "${IBL_PATH_ALYX}/alyx/$fx"
	done
}

update_alyx() {
	echo "# => updating Alyx"

	check_db ${PGDATABASE} -e
	check_db_usr ${PGUSER} -e

	echo "# ==> makemigrations"
	manage_alyx makemigrations

	echo "# ===> migrating"
	manage_alyx migrate

	load_alyx_fixtures

	echo "# ==> setting db permissions"
	manage_alyx set_db_permissions

	echo "# ==> setting user permissions"
	manage_alyx set_user_permissions
}

test_alyx() {
	(
		cd "${IBL_PATH_ALYX}/alyx"
		manage_alyx test --timing --no-input --nomigrations 2>&1 |
			tee "${IBL_PATH_DATA}/alyx/tests.log"
	)
}

sql_dump_load() {
	local dmp_="${1:-${ALYX_DUMP_FILE}}"
	local dbs_="${2:-${PGDATABASE}}"
	gzip -dc "$dmp_" | psql -d "$dbs_"
}

rename_dbs() {
	check_db "${PGDATABASE}_old" >/dev/null
	if [[ ${DB_NAME_EXISTS} -eq 1 ]]; then
		echo "# => dropping ${PGDATABASE}_old"
		dropdb "${PGDATABASE}_old" || err_exit "couldn't drop ${PGDATABASE}_old"
	fi

	# psql -d postgres -c "DROP DATABASE alyxdb WITH (FORCE)"
	echo "# ==> renaming ${PGDATABASE} to ${PGDATABASE}_old"
	psql -d postgres -c "ALTER DATABASE \"${PGDATABASE}\" RENAME TO \"${PGDATABASE}_old\";" >/dev/null ||
		echo "couldn't rename ${PGDATABASE} to ${PGDATABASE}_old"

	echo "# ===> creating new ${PGDATABASE}"
	createdb "${PGDATABASE}" || err_exit "couldn't create ${PGDATABASE} db"
}

reset_alyx() {
	echo "# => resetting database"
	rm -f "${db_loaded_file}"
	manage_alyx reset_db --noinput -v 3
}

load_db() {
	check_db ${PGDATABASE} -e
	local db_was_loaded=false
	local do_db_reset=false
	[[ "$1" = "--reset" ]] && do_db_reset=true

	if [[ ${do_db_reset} = true ]]; then
		reset_alyx
	fi

	if [[ -f "${db_loaded_file}" ]]; then
		echo "# => database already loaded, skipping load"
	else
		if [[ -f "${ALYX_DUMP_FILE}" ]]; then
			echo "# => loading database ${ALYX_DUMP_FILE}"
			sql_dump_load
			db_was_loaded=true
		else
			echo "# Warning: DB dump file '${ALYX_DUMP_FILE}' does not exist\!" \
				"Skipping load."
		fi
	fi

	if [[ ${db_was_loaded} = true ]] || [[ ${do_db_reset} = true ]]; then
		update_alyx
		touch ${IBL_PATH_ALYX}/alyx/alyx/settings.py
	fi

	[[ ${db_was_loaded} = true ]] && echo "${ALYX_DUMP_FILE}" >"${db_loaded_file}"
}

dump_json() {
	if [[ ! -f "${db_loaded_file}" ]]; then
		echo "# => database not loaded - skipping json dump."
	else
		local json_dump_file="${ALYX_DUMP_DIR}/json/alyx_full.json"

		[[ -f "${json_dump_file}" ]] &&
			mv -f "${json_dump_file}" "${json_dump_file}.last"

		echo "# => dumping db as JSON to ${json_dump_file}"
		manage_alyx dumpdata \
			-e contenttypes -e auth.permission \
			-e reversion.version -e reversion.revision -e admin.logentry \
			-e actions.ephyssession \
			-e actions.notification \
			-e actions.notificationrule \
			-e actions.virusinjection \
			-e data.download \
			-e experiments.brainregion \
			-e jobs.task \
			-e misc.note \
			-e subjects.subjectrequest \
			--indent 1 -o "${json_dump_file}"
	fi
}

dump_sql() {
	echo "# => performing sql backup"
	pg_dump -cOx -U ${PGUSER} -h ${PGHOST} -d ${PGDATABASE} \
		-f "${ALYX_DUMP_DIR}/backup/alyx_full.sql"
	echo "# ==> zipping sql backup"
	gzip -f "${ALYX_DUMP_DIR}/backup/alyx_full.sql"
}

kill_server() {
	echo "# => stopping alyx"
	sudo whoami >/dev/null
	sudo a2dissite -q 001-alyx
	sudo a2dismod -q wsgi
	sudo service apache2 stop >/dev/null
	sudo pkill -f "runserver --insecure 0.0.0.0:${ALYX_PORT}"
	rm -vf "${alyx_server_start_file}"
	ps axuww | grep runserver
}

start_server() {
	echo "# => starting alyx"
	[[ -z "${ALYX_PORT}" ]] && err_exit "port '${ALYX_PORT}' from ALYX_PORT is empty"
	sudo service apache2 restart >/dev/null
	source /etc/apache2/envvars
	sudo a2enconf servername
	sudo a2enmod -q wsgi
	sudo a2ensite -q 001-alyx
	sudo service apache2 reload >/dev/null
	sleep 3
	touch "${alyx_server_start_file}"
	manage_alyx runserver --insecure 0.0.0.0:${ALYX_PORT}
}

check_server() {
	echo "# => checking alyx"
	manage_alyx check --database default
	manage_alyx check
	[[ $(netstat -ano | grep "0.0.0.0:${ALYX_PORT}") ]] ||
		err_exit "server not running at 0.0.0.0:${ALYX_PORT}"
	[[ -f "${alyx_server_start_file}" ]] ||
		err_exit "alyx_start_server file not found."
}

# Routines
# --------

init_db() {
	lock_alyx_op
	create_dbs
	config_alyx
	update_alyx
	create_su
	lock_alyx_op -r
}

fetch_and_load_db() {
	lock_alyx_op -c
	fetch_dump
	load_db
}

fetch_and_reload_db() {
	lock_alyx_op -c
	fetch_dump
	load_db --reset
}

www() {
	init_db
	fetch_and_load_db
	start_server
}

www_no_load() {
	init_db
	start_server
}

# Start operations ---------------------------------------------------------------------

# switch to appropriate python environment
conda activate ${CONDA_ENV_USER}

# run sequence of operations specified by user
run_function_seq "${OPS_SEQ[@]}"
